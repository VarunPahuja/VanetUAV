{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1c553d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import warnings\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c628eafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (212883, 65) | Test Shape: (70191, 65)\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"../data/processed/cicids_10pct_pruned.csv\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "train_files = [\n",
    "    \"Monday-WorkingHours.pcap_ISCX.csv\",\n",
    "    \"Tuesday-WorkingHours.pcap_ISCX.csv\",\n",
    "    \"Wednesday-workingHours.pcap_ISCX.csv\",\n",
    "    \"Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\",\n",
    "    \"Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\"\n",
    "]\n",
    "\n",
    "test_files = [\n",
    "    \"Friday-WorkingHours-Morning.pcap_ISCX.csv\",\n",
    "    \"Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\",\n",
    "    \"Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\"\n",
    "]\n",
    "\n",
    "df[\"target\"] = (df[\"Label\"] != \"BENIGN\").astype(int)\n",
    "\n",
    "df_train = df[df[\"source_file\"].isin(train_files)].copy()\n",
    "df_test  = df[df[\"source_file\"].isin(test_files)].copy()\n",
    "\n",
    "print(f\"Train Shape: {df_train.shape} | Test Shape: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6bb0aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "META_COLS = [\n",
    "    \"Label\", \"label_bin\", \"label_binary\", \"source_file\", \n",
    "    \"day\", \"attack_group\", \"target\"\n",
    "]\n",
    "\n",
    "X_train_raw = df_train.drop(columns=META_COLS).select_dtypes(include=[np.number])\n",
    "y_train = df_train[\"target\"]\n",
    "\n",
    "X_test_raw = df_test.drop(columns=META_COLS).select_dtypes(include=[np.number])\n",
    "y_test = df_test[\"target\"]\n",
    "\n",
    "# Handle Inf/NaN before scaling\n",
    "X_train_raw = X_train_raw.replace([np.inf, -np.inf], np.nan)\n",
    "X_test_raw  = X_test_raw.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "])\n",
    "\n",
    "X_train = pipeline.fit_transform(X_train_raw)\n",
    "X_test  = pipeline.transform(X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e69d21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_clients_dirichlet(X, y, num_clients, alpha=0.1):\n",
    "    \"\"\"\n",
    "    Non-IID split using Dirichlet distribution.\n",
    "    \"\"\"\n",
    "    if isinstance(y, pd.Series):\n",
    "        y = y.to_numpy()\n",
    "\n",
    "    num_classes = len(np.unique(y))\n",
    "    class_indices = {c: np.where(y == c)[0] for c in range(num_classes)}\n",
    "\n",
    "    client_indices = [[] for _ in range(num_clients)]\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        np.random.shuffle(class_indices[c])\n",
    "        proportions = np.random.dirichlet(alpha * np.ones(num_clients))\n",
    "        proportions = (np.cumsum(proportions) * len(class_indices[c])).astype(int)[:-1]\n",
    "        splits = np.split(class_indices[c], proportions)\n",
    "\n",
    "        for i in range(num_clients):\n",
    "            client_indices[i].extend(splits[i])\n",
    "\n",
    "    clients = []\n",
    "    for idxs in client_indices:\n",
    "        if len(idxs) > 0:\n",
    "            clients.append((X[idxs], y[idxs]))\n",
    "\n",
    "    return clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfddd5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Non-IID Dirichlet split (alpha=0.1)\n",
      "Client 00: {np.int64(0): np.int64(9761)}\n",
      "Client 01: {np.int64(0): np.int64(76311), np.int64(1): np.int64(1)}\n",
      "Client 02: {np.int64(0): np.int64(1438), np.int64(1): np.int64(425)}\n",
      "Client 03: {np.int64(0): np.int64(2070), np.int64(1): np.int64(2)}\n",
      "Client 04: {np.int64(0): np.int64(97)}\n",
      "Client 05: {np.int64(1): np.int64(110)}\n",
      "Client 06: {np.int64(0): np.int64(36846), np.int64(1): np.int64(1042)}\n",
      "Client 07: {np.int64(0): np.int64(128), np.int64(1): np.int64(29)}\n",
      "Client 08: {np.int64(0): np.int64(3)}\n",
      "Client 09: {np.int64(0): np.int64(59386), np.int64(1): np.int64(25234)}\n"
     ]
    }
   ],
   "source": [
    "NUM_CLIENTS = 10\n",
    "ALPHA = 0.1   # Strong Non-IID\n",
    "\n",
    "clients = split_clients_dirichlet(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    NUM_CLIENTS,\n",
    "    alpha=ALPHA\n",
    ")\n",
    "\n",
    "print(f\"\\nNon-IID Dirichlet split (alpha={ALPHA})\")\n",
    "for i, (_, y_c) in enumerate(clients):\n",
    "    unique, counts = np.unique(y_c, return_counts=True)\n",
    "    print(f\"Client {i:02d}: {dict(zip(unique, counts))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fc0e3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    \"\"\"\n",
    "    ENHANCEMENT: \n",
    "    1. Increased max_iter to 10 (helps local convergence).\n",
    "    2. Added class_weight='balanced' (fixes 80% Benign bias).\n",
    "    \"\"\"\n",
    "    return LogisticRegression(\n",
    "        max_iter=10,        \n",
    "        solver=\"lbfgs\",\n",
    "        warm_start=True,\n",
    "        class_weight='balanced',  # <--- CRITICAL FOR IMBALANCE\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "def local_train(global_model, X_local, y_local):\n",
    "    # skip degenerate clients (must have at least 1 class)\n",
    "    # Note: Ideally needs 2 classes, but sklearn can handle 1 with warnings if we are careful\n",
    "    if len(np.unique(y_local)) < 1: \n",
    "        return None\n",
    "        \n",
    "    model = copy.deepcopy(global_model)\n",
    "    try:\n",
    "        model.fit(X_local, y_local)\n",
    "        return model\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def fedavg_m_update(global_model, client_models, eta=0.8):\n",
    "    \"\"\"\n",
    "    ENHANCEMENT: Global Momentum.\n",
    "    Instead of hard replacement, we blend old global weights with new average.\n",
    "    global_new = (1-eta)*global_old + eta*average(clients)\n",
    "    \"\"\"\n",
    "    if not client_models:\n",
    "        return global_model\n",
    "\n",
    "    avg_coef = np.mean(np.stack([m.coef_ for m in client_models]), axis=0)\n",
    "    avg_intercept = np.mean(np.stack([m.intercept_ for m in client_models]), axis=0)\n",
    "\n",
    "    # Momentum update\n",
    "    global_model.coef_ = (1 - eta) * global_model.coef_ + eta * avg_coef\n",
    "    global_model.intercept_ = (1 - eta) * global_model.intercept_ + eta * avg_intercept\n",
    "\n",
    "    return global_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b51c5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Enhanced Non-IID FL | Alpha: 0.1 | Server LR: 0.8\n",
      "Round 01 | Acc: 0.6951 | F1: 0.4140 | AUC: 0.8439\n",
      "Round 02 | Acc: 0.6940 | F1: 0.4105 | AUC: 0.8453\n",
      "Round 03 | Acc: 0.6951 | F1: 0.4135 | AUC: 0.8463\n",
      "Round 04 | Acc: 0.6949 | F1: 0.4130 | AUC: 0.8494\n",
      "Round 05 | Acc: 0.6950 | F1: 0.4133 | AUC: 0.8496\n",
      "Round 06 | Acc: 0.6951 | F1: 0.4135 | AUC: 0.8510\n",
      "Round 07 | Acc: 0.6950 | F1: 0.4134 | AUC: 0.8513\n",
      "Round 08 | Acc: 0.6950 | F1: 0.4133 | AUC: 0.8515\n",
      "Round 09 | Acc: 0.6949 | F1: 0.4129 | AUC: 0.8515\n",
      "Round 10 | Acc: 0.6949 | F1: 0.4129 | AUC: 0.8517\n",
      "Round 11 | Acc: 0.6949 | F1: 0.4129 | AUC: 0.8523\n",
      "Round 12 | Acc: 0.6949 | F1: 0.4129 | AUC: 0.8518\n",
      "Round 13 | Acc: 0.6949 | F1: 0.4130 | AUC: 0.8523\n",
      "Round 14 | Acc: 0.6950 | F1: 0.4134 | AUC: 0.8515\n",
      "Round 15 | Acc: 0.6951 | F1: 0.4134 | AUC: 0.8510\n",
      "Round 16 | Acc: 0.6951 | F1: 0.4134 | AUC: 0.8522\n",
      "Round 17 | Acc: 0.6949 | F1: 0.4130 | AUC: 0.8529\n",
      "Round 18 | Acc: 0.6950 | F1: 0.4132 | AUC: 0.8530\n",
      "Round 19 | Acc: 0.6950 | F1: 0.4131 | AUC: 0.8507\n",
      "Round 20 | Acc: 0.6949 | F1: 0.4129 | AUC: 0.8527\n"
     ]
    }
   ],
   "source": [
    "ROUNDS = 20\n",
    "SERVER_LR = 0.8 # Slightly conservative update rate for Non-IID\n",
    "\n",
    "global_model = init_model()\n",
    "\n",
    "# Warm start (optional but recommended)\n",
    "init_idx = np.random.choice(len(X_train), size=2000, replace=False)\n",
    "global_model.fit(X_train[init_idx], y_train.iloc[init_idx])\n",
    "\n",
    "print(f\"\\nStarting Enhanced Non-IID FL | Alpha: {ALPHA} | Server LR: {SERVER_LR}\")\n",
    "\n",
    "for rnd in range(ROUNDS):\n",
    "    client_models = []\n",
    "\n",
    "    for X_c, y_c in clients:\n",
    "        local_model = local_train(global_model, X_c, y_c)\n",
    "        if local_model is not None:\n",
    "            client_models.append(local_model)\n",
    "\n",
    "    # Enhanced Aggregation\n",
    "    global_model = fedavg_m_update(global_model, client_models, eta=SERVER_LR)\n",
    "\n",
    "    # ---- evaluation ----\n",
    "    y_pred = global_model.predict(X_test)\n",
    "    y_prob = global_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1  = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "    print(\n",
    "        f\"Round {rnd+1:02d} | \"\n",
    "        f\"Acc: {acc:.4f} | \"\n",
    "        f\"F1: {f1:.4f} | \"\n",
    "        f\"AUC: {auc:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea371786",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
