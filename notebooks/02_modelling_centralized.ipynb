{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49adfebf",
   "metadata": {},
   "source": [
    "# Centralized Baseline Models (Leakage-Safe)\n",
    "\n",
    "This notebook provides clean, reproducible baseline models for CICIDS2017 intrusion detection.\n",
    "\n",
    "**Key Features:**\n",
    "- ✅ Proper train/validation/test split (no leakage)\n",
    "- ✅ All preprocessing in sklearn Pipeline (federated-ready)\n",
    "- ✅ PCA fitted on training data only\n",
    "- ✅ Threshold tuning on validation set\n",
    "- ✅ Single evaluation on test set\n",
    "\n",
    "**Data Split Strategy:**\n",
    "- Training: Monday-Thursday files\n",
    "- Validation: 20% holdout from training\n",
    "- Test: Friday files (untouched until final evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71543256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f58df1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: d:\\Coding\\VanetUAV\\data\\processed\\cicids_10pct_stratified.csv\n",
      "Dataset shape: (283074, 84)\n"
     ]
    }
   ],
   "source": [
    "# Project-relative paths (no more Windows absolute paths)\n",
    "PROJECT_ROOT = Path().cwd().parent\n",
    "DATA_PATH = PROJECT_ROOT / \"data\" / \"processed\" / \"cicids_10pct_stratified.csv\"\n",
    "\n",
    "print(f\"Loading data from: {DATA_PATH}\")\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(f\"Dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bb7db3",
   "metadata": {},
   "source": [
    "## 1. Clean Data Split (Training Files vs Test Files)\n",
    "\n",
    "**Critical:** We must split by source file FIRST, before any preprocessing, to avoid temporal leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9efa3545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (212883, 85)\n",
      "Test data shape: (70191, 85)\n",
      "Training attack rate: 0.126\n",
      "Test attack rate: 0.412\n"
     ]
    }
   ],
   "source": [
    "# Define temporal split by day (Monday-Thursday = train, Friday = test)\n",
    "train_files = [\n",
    "    \"Monday-WorkingHours.pcap_ISCX.csv\",\n",
    "    \"Tuesday-WorkingHours.pcap_ISCX.csv\", \n",
    "    \"Wednesday-workingHours.pcap_ISCX.csv\",\n",
    "    \"Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\",\n",
    "    \"Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\"\n",
    "]\n",
    "\n",
    "test_files = [\n",
    "    \"Friday-WorkingHours-Morning.pcap_ISCX.csv\",\n",
    "    \"Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\", \n",
    "    \"Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\"\n",
    "]\n",
    "\n",
    "# Create clean binary target\n",
    "df[\"target\"] = (df[\"Label\"] != \"BENIGN\").astype(int)\n",
    "\n",
    "# Split data by files\n",
    "df_train_raw = df[df[\"source_file\"].isin(train_files)].copy()\n",
    "df_test = df[df[\"source_file\"].isin(test_files)].copy()\n",
    "\n",
    "print(f\"Training data shape: {df_train_raw.shape}\")\n",
    "print(f\"Test data shape: {df_test.shape}\")\n",
    "print(f\"Training attack rate: {df_train_raw['target'].mean():.3f}\")\n",
    "print(f\"Test attack rate: {df_test['target'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958aba2e",
   "metadata": {},
   "source": [
    "## 2. Feature Preparation (Training Data Only)\n",
    "\n",
    "**Critical:** All preprocessing steps must be fitted on training data only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d40cefc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (212883, 78)\n",
      "Feature columns: int64      54\n",
      "float64    24\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define metadata columns to exclude\n",
    "META_COLS = [\"Label\", \"source_file\", \"day\", \"attack_group\", \"target\"]\n",
    "if \"label_bin\" in df.columns:\n",
    "    META_COLS.append(\"label_bin\")\n",
    "if \"label_binary\" in df.columns:\n",
    "    META_COLS.append(\"label_binary\")\n",
    "\n",
    "# Extract feature matrix from training data\n",
    "X_train_raw = df_train_raw.drop(columns=META_COLS)\n",
    "y_train_raw = df_train_raw[\"target\"]\n",
    "\n",
    "# Extract test features (for final evaluation only)\n",
    "X_test = df_test.drop(columns=META_COLS)\n",
    "y_test = df_test[\"target\"]\n",
    "\n",
    "print(f\"Feature matrix shape: {X_train_raw.shape}\")\n",
    "print(f\"Feature columns: {X_train_raw.dtypes.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59ccc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean features: keep only numeric columns\n",
    "numeric_features = X_train_raw.select_dtypes(include=[np.number]).columns.tolist()\n",
    "X_train_raw = X_train_raw[numeric_features]\n",
    "X_test = X_test[numeric_features]\n",
    "\n",
    "print(f\"Numeric features: {len(numeric_features)}\")\n",
    "print(f\"Training shape after numeric filter: {X_train_raw.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea4925f",
   "metadata": {},
   "source": [
    "## 3. Train/Validation Split\n",
    "\n",
    "Split training data into train/validation for threshold tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e343d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final split:\n",
      "  Train: 170306 samples, attack rate: 0.126\n",
      "  Val:   42577 samples, attack rate: 0.126\n",
      "  Test:  70191 samples, attack rate: 0.412\n"
     ]
    }
   ],
   "source": [
    "# Create train/validation split from training data\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_raw, y_train_raw, \n",
    "    test_size=0.2, \n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y_train_raw\n",
    ")\n",
    "\n",
    "print(f\"Final split:\")\n",
    "print(f\"  Train: {X_train.shape[0]} samples, attack rate: {y_train.mean():.3f}\")\n",
    "print(f\"  Val:   {X_val.shape[0]} samples, attack rate: {y_val.mean():.3f}\") \n",
    "print(f\"  Test:  {X_test.shape[0]} samples, attack rate: {y_test.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a163a1",
   "metadata": {},
   "source": [
    "## 4. Preprocessing Pipeline (Leakage-Safe)\n",
    "\n",
    "**This pipeline will be reusable for federated learning clients.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8147275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created preprocessing pipelines:\n",
      "  - Without PCA: ['imputer', 'scaler']\n",
      "  - With PCA (25): ['imputer', 'scaler', 'pca']\n"
     ]
    }
   ],
   "source": [
    "# Create preprocessing pipeline that handles inf/nan and performs PCA\n",
    "def create_preprocessing_pipeline(n_components=25):\n",
    "    \"\"\"Create a complete preprocessing pipeline.\n",
    "    \n",
    "    Args:\n",
    "        n_components: Number of PCA components (None = no PCA)\n",
    "    \"\"\"\n",
    "    steps = [\n",
    "        ('imputer', SimpleImputer(strategy='median')),  # Handle inf/nan\n",
    "        ('scaler', StandardScaler()),\n",
    "    ]\n",
    "    \n",
    "    if n_components is not None:\n",
    "        steps.append(('pca', PCA(n_components=n_components, random_state=RANDOM_STATE)))\n",
    "    \n",
    "    return Pipeline(steps)\n",
    "\n",
    "# Test both with and without PCA\n",
    "pipeline_no_pca = create_preprocessing_pipeline(n_components=None)\n",
    "pipeline_pca = create_preprocessing_pipeline(n_components=25)\n",
    "\n",
    "print(\"Created preprocessing pipelines:\")\n",
    "print(f\"  - Without PCA: {[step[0] for step in pipeline_no_pca.steps]}\")\n",
    "print(f\"  - With PCA (25): {[step[0] for step in pipeline_pca.steps]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01e908d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed shapes:\n",
      "  Train: (170306, 25)\n",
      "  Val:   (42577, 25)\n",
      "  Test:  (70191, 25)\n",
      "PCA explained variance (25 components): 0.958\n"
     ]
    }
   ],
   "source": [
    "# Replace inf with NaN for proper imputation\n",
    "X_train_clean = X_train.replace([np.inf, -np.inf], np.nan)\n",
    "X_val_clean = X_val.replace([np.inf, -np.inf], np.nan)\n",
    "X_test_clean = X_test.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Fit preprocessing on training data only\n",
    "X_train_processed = pipeline_pca.fit_transform(X_train_clean)\n",
    "X_val_processed = pipeline_pca.transform(X_val_clean)\n",
    "X_test_processed = pipeline_pca.transform(X_test_clean)\n",
    "\n",
    "print(f\"Processed shapes:\")\n",
    "print(f\"  Train: {X_train_processed.shape}\")\n",
    "print(f\"  Val:   {X_val_processed.shape}\")\n",
    "print(f\"  Test:  {X_test_processed.shape}\")\n",
    "\n",
    "# Check PCA explained variance\n",
    "pca_explained_var = pipeline_pca.named_steps['pca'].explained_variance_ratio_.cumsum()\n",
    "print(f\"PCA explained variance (25 components): {pca_explained_var[-1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0807cb2b",
   "metadata": {},
   "source": [
    "## 5. Baseline Models\n",
    "\n",
    "Train Logistic Regression and Random Forest on the clean pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3be82eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Coding\\VanetUAV\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models trained successfully\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "lr.fit(X_train_processed, y_train)\n",
    "\n",
    "# Train Random Forest\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=20, \n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    class_weight='balanced',\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train_processed, y_train)\n",
    "\n",
    "print(\"Models trained successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea3b137",
   "metadata": {},
   "source": [
    "## 6. Threshold Tuning (Validation Set Only)\n",
    "\n",
    "**Critical:** We tune thresholds on validation set, never on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4cb622a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results:\n",
      "                model  threshold  accuracy  attack_precision  attack_recall  \\\n",
      "0  LogisticRegression        0.1     0.874             0.499          0.922   \n",
      "1        RandomForest        0.1     0.991             0.936          0.999   \n",
      "2  LogisticRegression        0.2     0.934             0.679          0.908   \n",
      "3        RandomForest        0.2     0.996             0.968          0.997   \n",
      "4  LogisticRegression        0.3     0.959             0.872          0.790   \n",
      "5        RandomForest        0.3     0.997             0.981          0.996   \n",
      "6  LogisticRegression        0.4     0.960             0.934          0.732   \n",
      "7        RandomForest        0.4     0.998             0.988          0.994   \n",
      "8  LogisticRegression        0.5     0.952             0.960          0.647   \n",
      "9        RandomForest        0.5     0.998             0.992          0.992   \n",
      "\n",
      "   attack_f1    auc  \n",
      "0      0.648  0.965  \n",
      "1      0.966  1.000  \n",
      "2      0.777  0.965  \n",
      "3      0.983  1.000  \n",
      "4      0.829  0.965  \n",
      "5      0.988  1.000  \n",
      "6      0.821  0.965  \n",
      "7      0.991  1.000  \n",
      "8      0.773  0.965  \n",
      "9      0.992  1.000  \n"
     ]
    }
   ],
   "source": [
    "# Get validation predictions\n",
    "y_val_prob_lr = lr.predict_proba(X_val_processed)[:, 1]\n",
    "y_val_prob_rf = rf.predict_proba(X_val_processed)[:, 1]\n",
    "\n",
    "def eval_threshold(y_true, y_prob, thresh, model_name=\"\"):\n",
    "    \"\"\"Evaluate model at specific threshold\"\"\"\n",
    "    y_pred = (y_prob >= thresh).astype(int)\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "    \n",
    "    attack_metrics = report['1']  # Class 1 = attack\n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'threshold': thresh,\n",
    "        'accuracy': report['accuracy'],\n",
    "        'attack_precision': attack_metrics['precision'],\n",
    "        'attack_recall': attack_metrics['recall'], \n",
    "        'attack_f1': attack_metrics['f1-score'],\n",
    "        'auc': auc\n",
    "    }\n",
    "\n",
    "# Test multiple thresholds on validation set\n",
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "val_results = []\n",
    "\n",
    "for thresh in thresholds:\n",
    "    val_results.append(eval_threshold(y_val, y_val_prob_lr, thresh, \"LogisticRegression\"))\n",
    "    val_results.append(eval_threshold(y_val, y_val_prob_rf, thresh, \"RandomForest\"))\n",
    "\n",
    "val_df = pd.DataFrame(val_results)\n",
    "print(\"Validation Results:\")\n",
    "print(val_df.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1142fdc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best thresholds (by validation F1):\n",
      "Logistic Regression: 0.3 (F1: 0.829)\n",
      "Random Forest: 0.5 (F1: 0.992)\n"
     ]
    }
   ],
   "source": [
    "# Select best thresholds based on F1 score\n",
    "best_lr_thresh = val_df[val_df['model'] == 'LogisticRegression'].sort_values('attack_f1', ascending=False).iloc[0]\n",
    "best_rf_thresh = val_df[val_df['model'] == 'RandomForest'].sort_values('attack_f1', ascending=False).iloc[0]\n",
    "\n",
    "print(\"Best thresholds (by validation F1):\")\n",
    "print(f\"Logistic Regression: {best_lr_thresh['threshold']:.1f} (F1: {best_lr_thresh['attack_f1']:.3f})\")\n",
    "print(f\"Random Forest: {best_rf_thresh['threshold']:.1f} (F1: {best_rf_thresh['attack_f1']:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25198f1",
   "metadata": {},
   "source": [
    "## 7. Final Test Evaluation (Once Only)\n",
    "\n",
    "**This is the only time we touch the test set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "556f0eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FINAL TEST RESULTS ===\n",
      "                model  threshold  accuracy  attack_precision  attack_recall  \\\n",
      "0  LogisticRegression        0.3     0.705             0.931          0.307   \n",
      "1        RandomForest        0.5     0.692             0.997          0.252   \n",
      "\n",
      "   attack_f1    auc  \n",
      "0      0.462  0.849  \n",
      "1      0.402  0.816  \n",
      "\n",
      "Logistic Regression (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.98      0.80     41269\n",
      "           1       0.93      0.31      0.46     28922\n",
      "\n",
      "    accuracy                           0.70     70191\n",
      "   macro avg       0.80      0.65      0.63     70191\n",
      "weighted avg       0.78      0.70      0.66     70191\n",
      "\n",
      "\n",
      "Random Forest (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.79     41269\n",
      "           1       1.00      0.25      0.40     28922\n",
      "\n",
      "    accuracy                           0.69     70191\n",
      "   macro avg       0.83      0.63      0.60     70191\n",
      "weighted avg       0.80      0.69      0.63     70191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final test predictions with optimal thresholds\n",
    "y_test_prob_lr = lr.predict_proba(X_test_processed)[:, 1]\n",
    "y_test_prob_rf = rf.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "# Apply best thresholds\n",
    "final_results = [\n",
    "    eval_threshold(y_test, y_test_prob_lr, best_lr_thresh['threshold'], \"LogisticRegression\"),\n",
    "    eval_threshold(y_test, y_test_prob_rf, best_rf_thresh['threshold'], \"RandomForest\")\n",
    "]\n",
    "\n",
    "final_df = pd.DataFrame(final_results)\n",
    "print(\"\\n=== FINAL TEST RESULTS ===\")\n",
    "print(final_df.round(3))\n",
    "\n",
    "# Detailed classification reports\n",
    "print(\"\\nLogistic Regression (Test Set):\")\n",
    "y_test_pred_lr = (y_test_prob_lr >= best_lr_thresh['threshold']).astype(int)\n",
    "print(classification_report(y_test, y_test_pred_lr))\n",
    "\n",
    "print(\"\\nRandom Forest (Test Set):\")\n",
    "y_test_pred_rf = (y_test_prob_rf >= best_rf_thresh['threshold']).astype(int)\n",
    "print(classification_report(y_test, y_test_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d5069e",
   "metadata": {},
   "source": [
    "## 8. Save Results & Pipeline\n",
    "\n",
    "Export results and the preprocessing pipeline for federated learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c820fa69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: d:\\Coding\\VanetUAV\\data\\processed\\centralized_baseline_results.csv\n",
      "Preprocessing pipeline saved to: d:\\Coding\\VanetUAV\\models\\preprocessing_pipeline.joblib\n",
      "\n",
      "✅ LEAKAGE-SAFE BASELINE COMPLETE\n",
      "✅ Pipeline ready for federated learning\n",
      "✅ Realistic performance metrics achieved\n"
     ]
    }
   ],
   "source": [
    "# Save final results\n",
    "results_path = PROJECT_ROOT / \"data\" / \"processed\" / \"centralized_baseline_results.csv\"\n",
    "final_df.to_csv(results_path, index=False)\n",
    "print(f\"Results saved to: {results_path}\")\n",
    "\n",
    "# Save preprocessing pipeline for federated learning\n",
    "import joblib\n",
    "pipeline_path = PROJECT_ROOT / \"models\" / \"preprocessing_pipeline.joblib\"\n",
    "pipeline_path.parent.mkdir(exist_ok=True)\n",
    "joblib.dump(pipeline_pca, pipeline_path)\n",
    "print(f\"Preprocessing pipeline saved to: {pipeline_path}\")\n",
    "\n",
    "print(\"\\n✅ LEAKAGE-SAFE BASELINE COMPLETE\")\n",
    "print(\"✅ Pipeline ready for federated learning\")\n",
    "print(\"✅ Realistic performance metrics achieved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34952708",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "**Data Split:** \n",
    "- Training: Mon-Thu files → Train/Val split (80/20)\n",
    "- Test: Friday files (untouched until final evaluation)\n",
    "\n",
    "**Pipeline:**\n",
    "- Imputation → StandardScaler → PCA(25) \n",
    "- Fitted on training data only\n",
    "- Reusable for federated clients\n",
    "\n",
    "**Models:** \n",
    "- Logistic Regression + Random Forest\n",
    "- Thresholds tuned on validation set\n",
    "- Final evaluation on test set\n",
    "\n",
    "**Next Steps:** Use the saved pipeline in federated learning experiments with the same preprocessing applied consistently across all clients."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
